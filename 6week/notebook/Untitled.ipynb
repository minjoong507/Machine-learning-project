{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression for a binary classification with a regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train  = np.loadtxt('training.txt', delimiter=',')\n",
    "data_test   = np.loadtxt('testing.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data_train[:,0]\n",
    "train_y = data_train[:,1]\n",
    "train_label = data_train[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = data_test[:,0]\n",
    "test_y = data_test[:,1]\n",
    "test_label = data_test[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic regression with a high dimensional feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + math.e ** -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.zeros([len(train_x), 100])\n",
    "\n",
    "for i in range(len(new_data)):\n",
    "    for j in range(10):\n",
    "        for k in range(10):\n",
    "            idx = j * 10 + k;\n",
    "            new_data[i, idx] = (train_x[i] ** j) * (train_y[i] ** k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephochs = 100\n",
    "m = len(train_label)\n",
    "learning_rate = 0.001\n",
    "lamda_list = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "Loss = []\n",
    "Loss_list = []\n",
    "coef = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = logistic(new_data.dot(coef))\n",
    "np.sum(h - train_label)/ m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 times running..\n",
      "10 times running..\n",
      "20 times running..\n",
      "30 times running..\n",
      "40 times running..\n",
      "50 times running..\n",
      "60 times running..\n",
      "70 times running..\n",
      "80 times running..\n",
      "90 times running..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n",
      "C:\\Users\\alber\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(ephochs):  \n",
    "        if i % 10 == 0:\n",
    "            print(str(i) + \" times running..\")\n",
    "        h = logistic(new_data.dot(coef))\n",
    "        Logistic_cost = - (1/m) * np.sum(train_label * np.log(h) + (1 - train_label) * np.log(1-h)) + 0.00001 * np.sum(coef ** 2) / 2\n",
    "        \n",
    "        Loss.append(Logistic_cost)\n",
    "        \n",
    "        coef[0] = coef[0] - learning_rate * np.sum((h - train_label) / m) + 0.00001 * coef[0]\n",
    "        for i in range(1, len(coef)):\n",
    "            coef[i] = coef[i] - learning_rate * (np.sum((h - train_label) * new_data[:,i] / m) + 0.00001 * coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.13574689e-05, 1.27674192e-04, 1.78287870e-04, 1.99610751e-04,\n",
       "       2.08914596e-04, 2.13020658e-04, 2.14907351e-04, 2.15805663e-04,\n",
       "       2.16247269e-04, 2.16470258e-04, 3.47341515e-04, 2.25904781e-04,\n",
       "       2.19893179e-04, 2.17583654e-04, 2.17021533e-04, 2.16838225e-04,\n",
       "       2.16773255e-04, 2.16746306e-04, 2.16733578e-04, 2.16726875e-04,\n",
       "       1.37836260e-04, 1.71713262e-04, 2.01991771e-04, 2.11231679e-04,\n",
       "       2.14580102e-04, 2.15831448e-04, 2.16332027e-04, 2.16542728e-04,\n",
       "       2.16635506e-04, 2.16677896e-04, 3.56702575e-04, 2.29429557e-04,\n",
       "       2.21122985e-04, 2.18000420e-04, 2.17146104e-04, 2.16862529e-04,\n",
       "       2.16767271e-04, 2.16734254e-04, 2.16722832e-04, 2.16718954e-04,\n",
       "       1.87205595e-04, 1.84349744e-04, 2.07122358e-04, 2.13363459e-04,\n",
       "       2.15515783e-04, 2.16256920e-04, 2.16531808e-04, 2.16639083e-04,\n",
       "       2.16683058e-04, 2.16701828e-04, 4.43966065e-04, 2.37396524e-04,\n",
       "       2.23245006e-04, 2.18596995e-04, 2.17347515e-04, 2.16935442e-04,\n",
       "       2.16795576e-04, 2.16745715e-04, 2.16727601e-04, 2.16720959e-04,\n",
       "       2.90643584e-04, 1.95975202e-04, 2.11085880e-04, 2.14728667e-04,\n",
       "       2.16051437e-04, 2.16475323e-04, 2.16624802e-04, 2.16679953e-04,\n",
       "       2.16701540e-04, 2.16710394e-04, 7.27517873e-04, 2.60860693e-04,\n",
       "       2.29435288e-04, 2.20303274e-04, 2.17899510e-04, 2.17123263e-04,\n",
       "       2.16863579e-04, 2.16771429e-04, 2.16737715e-04, 2.16725070e-04,\n",
       "       6.85558297e-04, 2.31174428e-04, 2.21623171e-04, 2.17948396e-04,\n",
       "       2.17173252e-04, 2.16880224e-04, 2.16777474e-04, 2.16739234e-04,\n",
       "       2.16725183e-04, 2.16720041e-04, 1.95768694e-03, 3.51631459e-04,\n",
       "       2.52310519e-04, 2.26768930e-04, 2.20002847e-04, 2.17840289e-04,\n",
       "       2.17120021e-04, 2.16866118e-04, 2.16773639e-04, 2.16738995e-04])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03362804283425293"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((h - train_label) * new_data[:,0] / m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -3.01314529e-13,\n",
       "       -3.88208193e-08, -7.34323047e-10, -2.22044605e-16, -1.31661881e-09,\n",
       "       -3.87850184e-02, -1.24113448e-06, -2.91574270e-03, -1.11056303e-01,\n",
       "       -2.89985541e-01, -3.30123150e-01, -3.45101671e-01, -4.80054155e-01,\n",
       "       -6.04920646e-01, -4.75695731e-01, -6.08450741e-01, -6.21377169e-01,\n",
       "       -6.60880884e-01, -6.47051701e-01, -6.41241224e-01, -6.77993387e-01,\n",
       "       -6.34737599e-01, -6.77332864e-01, -6.80925265e-01, -6.80374232e-01,\n",
       "       -6.84294166e-01, -6.83491761e-01, -6.86762436e-01, -6.88369725e-01,\n",
       "       -6.86934337e-01, -6.90777822e-01, -6.90722907e-01, -6.84334772e-01,\n",
       "       -6.86860004e-01, -6.96973962e-01, -6.87600815e-01, -6.87209294e-01,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02,\n",
       "       -2.24766381e-02, -2.24766381e-02, -2.24766381e-02, -2.24766381e-02])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(h) * train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 times running..\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-c67afa343828>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogistic_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mcoef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlamda\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, lamda in enumerate(lamda_list):\n",
    "    Loss = []\n",
    "    accuracy = []\n",
    "    coef = np.zeros(100)\n",
    "    coef_list = np.zeros((10,10)).tolist()\n",
    "    t0 = 0\n",
    "\n",
    "    for i in range(ephochs):  \n",
    "        if i % 1000 == 0:\n",
    "            print(str(i) + \" times running..\")\n",
    "        h = np.array(logistic(new_data.dot(coef) + t0))\n",
    "        Logistic_cost = - (1/m) * np.sum(train_label * np.log(h) + (1-train_label) * np.log(1-h)) + lamda * (t0 ** 2 + np.sum(coef ** 2))\n",
    "        \n",
    "        Loss.append(Logistic_cost)\n",
    "        \n",
    "        t0 = t0 - learning_rate * np.sum((h - label) / m)\n",
    "        for i in range(1, len(coef)):\n",
    "            coef[i] = coef[i] - learning_rate * (np.sum((h - label) * new_data[:,i] / m) + lamda * coef[i])\n",
    "    \n",
    "    X, Y = mesh()\n",
    "    Z  = t0\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            if i == 0 and j == 0:\n",
    "                continue\n",
    "            Z += coef[i * 10 + j - 1] * (X ** i) * (Y ** j)\n",
    "    tmp = [X,Y,Z]\n",
    "    result.append(tmp)\n",
    "    Loss_list.append(Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
