{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,)),  # mean value = 0.1307, standard deviation value = 0.3081\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('MNIST', train=True, download=False, transform=transforms.ToTensor()),\n",
    "    batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('MNIST', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification(\n",
       "  (classifier1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (classifier2): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=100, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (classifier3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classification, self).__init__()\n",
    "        \n",
    "        # construct layers for a neural network\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=20*20),\n",
    "            nn.Sigmoid(),\n",
    "        ) \n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(in_features=20*20, out_features=10*10),\n",
    "            nn.Sigmoid(),\n",
    "        ) \n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.Linear(in_features=10*10, out_features=10),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        ) \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):                 # [batchSize, 1, 28, 28]\n",
    "        x = inputs.view(inputs.size(0), -1)    # [batchSize, 28*28]\n",
    "        x = self.classifier1(x)                # [batchSize, 20*20]\n",
    "        x = self.classifier2(x)                # [batchSize, 10*10]\n",
    "        out = self.classifier3(x)              # [batchSize, 10]\n",
    "        \n",
    "        return out\n",
    "\n",
    "net = classification()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_value = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=learning_rate_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 8001\tLoss: 2.311\tAccuracy: 6.250\n",
      "Train Step: 8004\tLoss: 2.298\tAccuracy: 18.750\n",
      "Train Step: 8007\tLoss: 2.285\tAccuracy: 18.750\n",
      "Train Step: 8010\tLoss: 2.283\tAccuracy: 18.750\n",
      "Train Step: 8013\tLoss: 2.342\tAccuracy: 6.250\n",
      "Train Step: 8016\tLoss: 2.280\tAccuracy: 18.750\n",
      "Train Step: 8019\tLoss: 2.311\tAccuracy: 18.750\n",
      "Train Step: 8022\tLoss: 2.337\tAccuracy: 9.375\n",
      "Train Step: 8025\tLoss: 2.225\tAccuracy: 18.750\n",
      "Train Step: 8028\tLoss: 2.260\tAccuracy: 18.750\n",
      "Train Step: 8031\tLoss: 2.331\tAccuracy: 18.750\n",
      "Train Step: 8034\tLoss: 2.291\tAccuracy: 12.500\n",
      "Train Step: 8037\tLoss: 2.377\tAccuracy: 3.125\n",
      "Train Step: 8040\tLoss: 2.359\tAccuracy: 12.500\n",
      "Train Step: 8043\tLoss: 2.269\tAccuracy: 15.625\n",
      "Train Step: 8046\tLoss: 2.328\tAccuracy: 6.250\n",
      "Train Step: 8049\tLoss: 2.377\tAccuracy: 12.500\n",
      "Train Step: 8052\tLoss: 2.340\tAccuracy: 3.125\n",
      "Train Step: 8055\tLoss: 2.442\tAccuracy: 3.125\n",
      "Train Step: 8058\tLoss: 2.337\tAccuracy: 9.375\n",
      "Train Step: 8061\tLoss: 2.323\tAccuracy: 15.625\n",
      "Train Step: 8064\tLoss: 2.331\tAccuracy: 9.375\n",
      "Train Step: 8067\tLoss: 2.428\tAccuracy: 0.000\n",
      "Train Step: 8070\tLoss: 2.325\tAccuracy: 3.125\n",
      "Train Step: 8073\tLoss: 2.374\tAccuracy: 3.125\n",
      "Train Step: 8076\tLoss: 2.323\tAccuracy: 12.500\n",
      "Train Step: 8079\tLoss: 2.405\tAccuracy: 6.250\n",
      "Train Step: 8082\tLoss: 2.339\tAccuracy: 15.625\n",
      "Train Step: 8085\tLoss: 2.439\tAccuracy: 9.375\n",
      "Train Step: 8088\tLoss: 2.398\tAccuracy: 6.250\n",
      "Train Step: 8091\tLoss: 2.365\tAccuracy: 9.375\n",
      "Train Step: 8094\tLoss: 2.285\tAccuracy: 9.375\n",
      "Train Step: 8097\tLoss: 2.420\tAccuracy: 6.250\n",
      "Train Step: 8100\tLoss: 2.312\tAccuracy: 9.375\n",
      "Train Step: 8103\tLoss: 2.374\tAccuracy: 9.375\n",
      "Train Step: 8106\tLoss: 2.291\tAccuracy: 9.375\n",
      "Train Step: 8109\tLoss: 2.279\tAccuracy: 12.500\n",
      "Train Step: 8112\tLoss: 2.331\tAccuracy: 3.125\n",
      "Train Step: 8115\tLoss: 2.336\tAccuracy: 18.750\n",
      "Train Step: 8118\tLoss: 2.359\tAccuracy: 9.375\n",
      "Train Step: 8121\tLoss: 2.302\tAccuracy: 12.500\n",
      "Train Step: 8124\tLoss: 2.282\tAccuracy: 12.500\n",
      "Train Step: 8127\tLoss: 2.374\tAccuracy: 6.250\n",
      "Train Step: 8130\tLoss: 2.339\tAccuracy: 6.250\n",
      "Train Step: 8133\tLoss: 2.306\tAccuracy: 9.375\n",
      "Train Step: 8136\tLoss: 2.354\tAccuracy: 12.500\n",
      "Train Step: 8139\tLoss: 2.352\tAccuracy: 12.500\n",
      "Train Step: 8142\tLoss: 2.335\tAccuracy: 9.375\n",
      "Train Step: 8145\tLoss: 2.419\tAccuracy: 9.375\n",
      "Train Step: 8148\tLoss: 2.278\tAccuracy: 15.625\n",
      "Train Step: 8151\tLoss: 2.339\tAccuracy: 12.500\n",
      "Train Step: 8154\tLoss: 2.264\tAccuracy: 12.500\n",
      "Train Step: 8157\tLoss: 2.322\tAccuracy: 9.375\n",
      "Train Step: 8160\tLoss: 2.366\tAccuracy: 9.375\n",
      "Train Step: 8163\tLoss: 2.371\tAccuracy: 9.375\n",
      "Train Step: 8166\tLoss: 2.254\tAccuracy: 21.875\n",
      "Train Step: 8169\tLoss: 2.415\tAccuracy: 9.375\n",
      "Train Step: 8172\tLoss: 2.415\tAccuracy: 3.125\n",
      "Train Step: 8175\tLoss: 2.253\tAccuracy: 21.875\n",
      "Train Step: 8178\tLoss: 2.400\tAccuracy: 9.375\n",
      "Train Step: 8181\tLoss: 2.370\tAccuracy: 12.500\n",
      "Train Step: 8184\tLoss: 2.325\tAccuracy: 15.625\n",
      "Train Step: 8187\tLoss: 2.250\tAccuracy: 15.625\n",
      "Train Step: 8190\tLoss: 2.353\tAccuracy: 6.250\n",
      "Train Step: 8193\tLoss: 2.387\tAccuracy: 12.500\n",
      "Train Step: 8196\tLoss: 2.307\tAccuracy: 6.250\n",
      "Train Step: 8199\tLoss: 2.366\tAccuracy: 12.500\n",
      "Train Step: 8202\tLoss: 2.341\tAccuracy: 15.625\n",
      "Train Step: 8205\tLoss: 2.287\tAccuracy: 6.250\n",
      "Train Step: 8208\tLoss: 2.387\tAccuracy: 6.250\n",
      "Train Step: 8211\tLoss: 2.359\tAccuracy: 6.250\n",
      "Train Step: 8214\tLoss: 2.421\tAccuracy: 6.250\n",
      "Train Step: 8217\tLoss: 2.311\tAccuracy: 12.500\n",
      "Train Step: 8220\tLoss: 2.290\tAccuracy: 15.625\n",
      "Train Step: 8223\tLoss: 2.322\tAccuracy: 12.500\n",
      "Train Step: 8226\tLoss: 2.447\tAccuracy: 9.375\n",
      "Train Step: 8229\tLoss: 2.314\tAccuracy: 6.250\n",
      "Train Step: 8232\tLoss: 2.362\tAccuracy: 25.000\n",
      "Train Step: 8235\tLoss: 2.337\tAccuracy: 9.375\n",
      "Train Step: 8238\tLoss: 2.328\tAccuracy: 12.500\n",
      "Train Step: 8241\tLoss: 2.417\tAccuracy: 12.500\n",
      "Train Step: 8244\tLoss: 2.289\tAccuracy: 9.375\n",
      "Train Step: 8247\tLoss: 2.427\tAccuracy: 6.250\n",
      "Train Step: 8250\tLoss: 2.335\tAccuracy: 9.375\n",
      "Train Step: 8253\tLoss: 2.351\tAccuracy: 15.625\n",
      "Train Step: 8256\tLoss: 2.320\tAccuracy: 6.250\n",
      "Train Step: 8259\tLoss: 2.426\tAccuracy: 9.375\n",
      "Train Step: 8262\tLoss: 2.396\tAccuracy: 12.500\n",
      "Train Step: 8265\tLoss: 2.277\tAccuracy: 12.500\n",
      "Train Step: 8268\tLoss: 2.335\tAccuracy: 3.125\n",
      "Train Step: 8271\tLoss: 2.294\tAccuracy: 12.500\n",
      "Train Step: 8274\tLoss: 2.299\tAccuracy: 15.625\n",
      "Train Step: 8277\tLoss: 2.410\tAccuracy: 9.375\n",
      "Train Step: 8280\tLoss: 2.388\tAccuracy: 12.500\n",
      "Train Step: 8283\tLoss: 2.342\tAccuracy: 12.500\n",
      "Train Step: 8286\tLoss: 2.374\tAccuracy: 9.375\n",
      "Train Step: 8289\tLoss: 2.319\tAccuracy: 18.750\n",
      "Train Step: 8292\tLoss: 2.366\tAccuracy: 9.375\n",
      "Train Step: 8295\tLoss: 2.337\tAccuracy: 6.250\n",
      "Train Step: 8298\tLoss: 2.263\tAccuracy: 18.750\n",
      "Train Step: 8301\tLoss: 2.398\tAccuracy: 3.125\n",
      "Train Step: 8304\tLoss: 2.314\tAccuracy: 15.625\n",
      "Train Step: 8307\tLoss: 2.376\tAccuracy: 9.375\n",
      "Train Step: 8310\tLoss: 2.344\tAccuracy: 12.500\n",
      "Train Step: 8313\tLoss: 2.316\tAccuracy: 9.375\n",
      "Train Step: 8316\tLoss: 2.346\tAccuracy: 6.250\n",
      "Train Step: 8319\tLoss: 2.387\tAccuracy: 12.500\n",
      "Train Step: 8322\tLoss: 2.330\tAccuracy: 6.250\n",
      "Train Step: 8325\tLoss: 2.307\tAccuracy: 9.375\n",
      "Train Step: 8328\tLoss: 2.320\tAccuracy: 12.500\n",
      "Train Step: 8331\tLoss: 2.392\tAccuracy: 6.250\n",
      "Train Step: 8334\tLoss: 2.364\tAccuracy: 6.250\n",
      "Train Step: 8337\tLoss: 2.262\tAccuracy: 18.750\n",
      "Train Step: 8340\tLoss: 2.257\tAccuracy: 9.375\n",
      "Train Step: 8343\tLoss: 2.359\tAccuracy: 12.500\n",
      "Train Step: 8346\tLoss: 2.380\tAccuracy: 6.250\n",
      "Train Step: 8349\tLoss: 2.355\tAccuracy: 6.250\n",
      "Train Step: 8352\tLoss: 2.429\tAccuracy: 6.250\n",
      "Train Step: 8355\tLoss: 2.300\tAccuracy: 9.375\n",
      "Train Step: 8358\tLoss: 2.326\tAccuracy: 6.250\n",
      "Train Step: 8361\tLoss: 2.304\tAccuracy: 6.250\n",
      "Train Step: 8364\tLoss: 2.336\tAccuracy: 12.500\n",
      "Train Step: 8367\tLoss: 2.298\tAccuracy: 12.500\n",
      "Train Step: 8370\tLoss: 2.233\tAccuracy: 12.500\n",
      "Train Step: 8373\tLoss: 2.311\tAccuracy: 15.625\n",
      "Train Step: 8376\tLoss: 2.424\tAccuracy: 12.500\n",
      "Train Step: 8379\tLoss: 2.420\tAccuracy: 6.250\n",
      "Train Step: 8382\tLoss: 2.224\tAccuracy: 12.500\n",
      "Train Step: 8385\tLoss: 2.267\tAccuracy: 18.750\n",
      "Train Step: 8388\tLoss: 2.341\tAccuracy: 15.625\n",
      "Train Step: 8391\tLoss: 2.341\tAccuracy: 15.625\n",
      "Train Step: 8394\tLoss: 2.429\tAccuracy: 9.375\n",
      "Train Step: 8397\tLoss: 2.355\tAccuracy: 9.375\n",
      "Train Step: 8400\tLoss: 2.342\tAccuracy: 9.375\n",
      "Train Step: 8403\tLoss: 2.290\tAccuracy: 18.750\n",
      "Train Step: 8406\tLoss: 2.416\tAccuracy: 6.250\n",
      "Train Step: 8409\tLoss: 2.435\tAccuracy: 3.125\n",
      "Train Step: 8412\tLoss: 2.350\tAccuracy: 15.625\n",
      "Train Step: 8415\tLoss: 2.339\tAccuracy: 9.375\n",
      "Train Step: 8418\tLoss: 2.310\tAccuracy: 12.500\n",
      "Train Step: 8421\tLoss: 2.441\tAccuracy: 3.125\n",
      "Train Step: 8424\tLoss: 2.356\tAccuracy: 0.000\n",
      "Train Step: 8427\tLoss: 2.345\tAccuracy: 6.250\n",
      "Train Step: 8430\tLoss: 2.350\tAccuracy: 9.375\n",
      "Train Step: 8433\tLoss: 2.381\tAccuracy: 3.125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-00e25d15185d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "i = 0\n",
    "\n",
    "for epoch in range(15):\n",
    "    for data, target in train_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()    # calc gradients\n",
    "        train_loss.append(loss)\n",
    "        optimizer.step()   # update gradients\n",
    "        prediction = output.data.max(1)[1]   # first column has actual prob.\n",
    "        accuracy = prediction.eq(target.data).sum()/batch_size*100\n",
    "        train_accu.append(accuracy)\n",
    "        if i % 3 == 0:\n",
    "            print('Train Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.3f}'.format(i, loss, accuracy))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 8 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification(\n",
       "  (classifier1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (classifier2): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=100, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (classifier3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classification, self).__init__()\n",
    "        \n",
    "        # construct layers for a neural network\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=20*20),\n",
    "            nn.Sigmoid(),\n",
    "        ) \n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(in_features=20*20, out_features=10*10),\n",
    "            nn.Sigmoid(),\n",
    "        ) \n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.Linear(in_features=10*10, out_features=10),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        ) \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):                 # [batchSize, 1, 28, 28]\n",
    "        x = inputs.view(inputs.size(0), -1)    # [batchSize, 28*28]\n",
    "        x = self.classifier1(x)                # [batchSize, 20*20]\n",
    "        x = self.classifier2(x)                # [batchSize, 10*10]\n",
    "        out = self.classifier3(x)              # [batchSize, 10]\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = classification()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('MNIST', train=True, download=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('MNIST', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 784])\n",
      "torch.Size([400])\n",
      "torch.Size([100, 400])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 0\tLoss: 2.330\tAccuracy: 18.750\n",
      "Train Step: 1000\tLoss: 2.300\tAccuracy: 12.500\n",
      "Train Step: 2000\tLoss: 2.292\tAccuracy: 12.500\n",
      "Train Step: 3000\tLoss: 2.271\tAccuracy: 34.375\n",
      "Train Step: 4000\tLoss: 2.267\tAccuracy: 12.500\n",
      "Train Step: 5000\tLoss: 2.182\tAccuracy: 21.875\n",
      "Train Step: 6000\tLoss: 1.899\tAccuracy: 43.750\n",
      "Train Step: 7000\tLoss: 1.404\tAccuracy: 56.250\n",
      "Train Step: 8000\tLoss: 1.420\tAccuracy: 53.125\n",
      "Train Step: 9000\tLoss: 1.155\tAccuracy: 65.625\n",
      "Train Step: 10000\tLoss: 0.895\tAccuracy: 75.000\n",
      "Train Step: 11000\tLoss: 0.908\tAccuracy: 81.250\n",
      "Train Step: 12000\tLoss: 0.982\tAccuracy: 68.750\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.train()\n",
    "train_loss = []\n",
    "train_accu = []\n",
    "i = 0\n",
    "for epoch in range(15):\n",
    "    for data, target in train_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()    # calc gradients\n",
    "        train_loss.append(loss.data)\n",
    "        optimizer.step()   # update gradients\n",
    "        prediction = output.data.max(1)[1]   # first column has actual prob.\n",
    "        accuracy = prediction.eq(target.data).sum()/batch_size*100\n",
    "        train_accu.append(accuracy)\n",
    "        if i % 1000 == 0:\n",
    "            print('Train Step: {}\\tLoss: {:.3f}\\tAccuracy: {:.3f}'.format(i, loss.data, accuracy))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
